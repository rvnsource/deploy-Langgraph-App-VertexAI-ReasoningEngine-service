{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea949af9-ba34-42ff-8dd1-9e93a2025716",
   "metadata": {},
   "source": [
    "### Install 3rd party packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d582ae8e-1b55-4f7d-951a-08245e55d389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet \\\n",
    "    \"google-cloud-aiplatform[langchain,reasoningengine]\" \\\n",
    "    langgraph \\\n",
    "    geopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e415b0de-4835-407d-94ae-05c912a2ca57",
   "metadata": {},
   "source": [
    "### Restart kernel runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66f09b3e-3409-4170-bd07-cd40ab8df621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de60b4ac-59c8-4730-aed6-f0c18875f720",
   "metadata": {},
   "source": [
    "### Authenticate with GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6ebe832-36f8-42fc-8b1a-d9bc14f55732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the environment variable to point to your service account key\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/ravi/.config/gcloud/genai-443318-637e44e3cf32.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db4ad7dc-a123-4225-8969-ebd304558a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"genai-443318\"\n",
    "LOCATION = \"us-central1\"\n",
    "STAGING_BUCKET = \"gs://reasoning-bucket-2\"\n",
    "\n",
    "import vertexai\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION, staging_bucket=STAGING_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7821e804-897a-48ea-9c19-1d8626cb432a",
   "metadata": {},
   "source": [
    "### Define tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b26d3c-3576-49b1-948d-fb57b185ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_product_details(product_name: str):\n",
    "    \"\"\"Gathers basic details about a product\"\"\"\n",
    "    details = {\n",
    "        \"smartphone\": \"A smartphone is a mobile phone with advanced computing capabilities.\",\n",
    "        \"speaker\": \"A speaker is an electroacoustic transducer that converts electrical audio signals into sound waves.\",\n",
    "        \"headphones\": \"Headphones are audio devices worn over or around the ears.\",\n",
    "        \"shoes\": \"Shoes are footwear designed to protect and comfort the human foot.\"\n",
    "    }\n",
    "    return details.get(product_name, \"Product details not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50064cfd-4704-4e2e-b700-7d330749e185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "@tool\n",
    "def get_weather(city: str):\n",
    "    \"\"\"Get weather details for the given city\"\"\"\n",
    "\n",
    "    latitude, longitude = get_lat_long(city)\n",
    "    api_url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,relativehumidity_2m,weathercode&hourly=temperature_2m,relativehumidity_2m,weathercode&daily=weathercode&temperature_2m_max,temperature_2m_min&windspeed_10m_max&precipitation_sum&rain_sum&showers_sum&snowfall_sum\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        data = response.json()\n",
    "\n",
    "        current_weather = data[\"current\"]\n",
    "        temperature = current_weather[\"temperature_2m\"]\n",
    "        humidity = current_weather[\"relativehumidity_2m\"]\n",
    "        weather_code = current_weather[\"weathercode\"]\n",
    "\n",
    "        # Map weather code to a descriptive string (optional)\n",
    "        weather_descriptions = {\n",
    "            0: \"Clear sky\",\n",
    "            1: \"Mainly clear\",\n",
    "            2: \"Partly cloudy\",\n",
    "            3: \"Overcast\",\n",
    "            45: \"Fog\",\n",
    "            48: \"Depositing rime fog\",\n",
    "            51: \"Light drizzle\",\n",
    "            53: \"Moderate drizzle\",\n",
    "            55: \"Dense drizzle\",\n",
    "            56: \"Light freezing drizzle\",\n",
    "            57: \"Dense freezing drizzle\",\n",
    "            61: \"Slight rain\",\n",
    "            63: \"Moderate rain\",\n",
    "            65: \"Heavy rain\",\n",
    "            66: \"Light freezing rain\",\n",
    "            67: \"Heavy freezing rain\",\n",
    "            71: \"Slight snow fall\",\n",
    "            73: \"Moderate snow fall\",\n",
    "            75: \"Heavy snow fall\",\n",
    "            77: \"Snow grains\",\n",
    "            80: \"Slight rain showers\",\n",
    "            81: \"Moderate rain showers\",\n",
    "            82: \"Violent rain showers\",\n",
    "            83: \"Slight snow showers\",\n",
    "            84: \"Heavy snow showers\",\n",
    "            85: \"Slight snow flurries\",\n",
    "            86: \"Heavy snow flurries\",\n",
    "            95: \"Slight or moderate thunderstorm\",\n",
    "            96: \"Thunderstorm with slight hail\",\n",
    "            99: \"Thunderstorm with heavy hail\"\n",
    "        }\n",
    "\n",
    "        weather_description = weather_descriptions.get(weather_code, \"Unknown\")\n",
    "\n",
    "        return f\"temperature: {temperature} humidity: {humidity} description: {weather_description} in {city} - Latitude {latitude}, Longitude {longitude}\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching weather data: {e}\")\n",
    "        return f\"Error fetching weather data: {e}\"\n",
    "\n",
    "\n",
    "import requests\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "def get_lat_long(city):\n",
    "    \"\"\"\n",
    "    Gets the latitude and longitude of a given city using the Nominatim geocoder.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the latitude and longitude, or None if the city is not found.\n",
    "    \"\"\"\n",
    "    geolocator = Nominatim(user_agent=\"my_geocoder\")\n",
    "    location = geolocator.geocode(city)\n",
    "\n",
    "    if location:\n",
    "        return location.latitude, location.longitude\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92abd1de-3318-4f5a-b490-67e6c3a6b2bb",
   "metadata": {},
   "source": [
    "### Define router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bbf78b7-2d5b-4bbd-8982-fbff0744e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "def router(state: List[BaseMessage]) -> Literal[\"get_product_details\", \"get_weather\", \"__end__\"]:\n",
    "    \"\"\"Initiates product details retrieval if the user asks for a product\"\"\"\n",
    "    # Get the tool_calls from the last message in the conversation history\n",
    "    tool_calls = state[-1].tool_calls\n",
    "\n",
    "    # If there are any tool_calls\n",
    "    if len(tool_calls):\n",
    "        # Return the name of the tool to be called\n",
    "        tool_name = tool_calls[0]['name']\n",
    "        return tool_name\n",
    "    else:\n",
    "        return \"__end__\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002b386a-cbc7-429c-b075-88a1e44591b4",
   "metadata": {},
   "source": [
    "### LangGraph Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea265c1d-f736-4b1c-919e-6636cd73d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langgraph.graph import END, MessageGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "class SimpleLangGraphApp:\n",
    "    def __init__(self, project: str, location: str) -> None:\n",
    "        self.project_id = project\n",
    "        self.location = location\n",
    "\n",
    "    def set_up(self) -> None:\n",
    "        model = ChatVertexAI(model=\"gemini-1.5-pro\")\n",
    "        model_with_tools = model.bind_tools([get_product_details, get_weather])\n",
    "\n",
    "        builder = MessageGraph()\n",
    "        builder.add_node(\"tools\", model_with_tools)\n",
    "\n",
    "        tool_node = ToolNode([get_product_details])\n",
    "        builder.add_node(\"get_product_details\", tool_node)\n",
    "        builder.add_edge(\"get_product_details\", END)\n",
    "\n",
    "\n",
    "        tool_node2 = ToolNode([get_weather])\n",
    "        builder.add_node(\"get_weather\", tool_node2)\n",
    "        builder.add_edge(\"get_weather\", END)\n",
    "\n",
    "        builder.set_entry_point(\"tools\")\n",
    "        builder.add_conditional_edges(\"tools\", router)\n",
    "\n",
    "        self.runnable = builder.compile()\n",
    "\n",
    "    # The query method will be used to send inputs to the agent\n",
    "    def query(self, message: str):\n",
    "        \"\"\"Query the application.\n",
    "\n",
    "        Args:\n",
    "            message (str): The user message.\n",
    "\n",
    "        Returns:\n",
    "            str: The LLM response.\n",
    "        \"\"\"\n",
    "        chat_history = self.runnable.invoke(HumanMessage(message))\n",
    "\n",
    "        return chat_history[-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060a7044-57ea-4fc8-a82c-924253fa5a78",
   "metadata": {},
   "source": [
    "### Local Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c26b47e-cb06-4bc7-83e7-80faa9f0e095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shoes are footwear designed to protect and comfort the human foot.\n",
      "Headphones are audio devices worn over or around the ears.\n",
      "temperature: 15.4 humidity: 72 description: Clear sky in New Delhi - Latitude 28.64308585, Longitude 77.21926705734865\n",
      "temperature: 24.5 humidity: 74 description: Mainly clear in Coimbatore - Latitude 11.0018115, Longitude 76.9628425\n",
      "temperature: -7.6 humidity: 39 description: Clear sky in New York - Latitude 40.7127281, Longitude -74.0060152\n",
      "```python\n",
      "def add_numbers(num1, num2):\n",
      "  \"\"\"Adds two numbers together\n",
      "\n",
      "  Args:\n",
      "    num1: The first number.\n",
      "    num2: The second number.\n",
      "\n",
      "  Returns:\n",
      "    The sum of the two numbers.\n",
      "  \"\"\"\n",
      "\n",
      "  return num1 + num2\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "agent = SimpleLangGraphApp(project=PROJECT_ID, location=LOCATION)\n",
    "agent.set_up()\n",
    "\n",
    "print(agent.query(message=\"Get product details for shoes.\"))\n",
    "print(agent.query(message=\"Get product details for headphones.\"))\n",
    "print(agent.query(message=\"Tell me about the weather in New Delhi.\"))\n",
    "print(agent.query(message=\"Tell me about the weather in Coimbatore.\"))\n",
    "print(agent.query(message=\"Tell me about the weather in New York.\"))\n",
    "print(agent.query(message=\"Write python code to add two numbers\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58ea5c9-0fa8-47b8-84ed-029224a092ea",
   "metadata": {},
   "source": [
    "### Deploy our LangGraph app (our AI agent) onto GCP VertexAI ReasoningEngine service "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b82e72-b524-4713-a9c6-567ece9981b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket reasoning-bucket-2\n",
      "Writing to gs://reasoning-bucket-2/reasoning_engine/reasoning_engine.pkl\n",
      "Writing to gs://reasoning-bucket-2/reasoning_engine/requirements.txt\n",
      "Creating in-memory tarfile of extra_packages\n",
      "Writing to gs://reasoning-bucket-2/reasoning_engine/dependencies.tar.gz\n",
      "Creating ReasoningEngine\n",
      "Create ReasoningEngine backing LRO: projects/28368249660/locations/us-central1/reasoningEngines/3743951441786568704/operations/6179668111638134784\n",
      "ReasoningEngine created. Resource name: projects/28368249660/locations/us-central1/reasoningEngines/3743951441786568704\n",
      "To use this ReasoningEngine in another session:\n",
      "reasoning_engine = vertexai.preview.reasoning_engines.ReasoningEngine('projects/28368249660/locations/us-central1/reasoningEngines/3743951441786568704')\n"
     ]
    }
   ],
   "source": [
    "from vertexai.preview import reasoning_engines\n",
    "remote_agent = reasoning_engines.ReasoningEngine.create(\n",
    "    SimpleLangGraphApp(project=PROJECT_ID, location=LOCATION),\n",
    "    requirements=[\n",
    "        \"google-cloud-aiplatform[langchain,reasoningengine]\",\n",
    "        \"langgraph\", \n",
    "        \"geopy\"        \n",
    "    ],\n",
    "    display_name=\"My AI agent for product and weather details\",\n",
    "    description=\"My AI agent for product and weather details\",\n",
    "    extra_packages=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e8718f0-2321-4df5-86bf-4d380d5dba80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temperature: 24.2 humidity: 75 description: Mainly clear in Coimbatore - Latitude 11.0018115, Longitude 76.9628425'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_agent.query(message=\"Tell me about the weather in Coimbatore.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ba1ea3a-983a-4804-95d2-93bab136a715",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_engine = vertexai.preview.reasoning_engines.ReasoningEngine('projects/28368249660/locations/us-central1/reasoningEngines/3743951441786568704')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74c75bf7-3cc3-48c1-9202-ab4bd50c834f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temperature: 24.2 humidity: 75 description: Mainly clear in Coimbatore - Latitude 11.0018115, Longitude 76.9628425'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_engine.query(message=\"Tell me about the weather in Coimbatore.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319cd06f-6cfa-43a3-8046-d58a35a700d8",
   "metadata": {},
   "source": [
    "### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0de90d0-292a-4fde-80fa-e20a82441495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting ReasoningEngine : projects/28368249660/locations/us-central1/reasoningEngines/3743951441786568704\n",
      "ReasoningEngine deleted. . Resource name: projects/28368249660/locations/us-central1/reasoningEngines/3743951441786568704\n",
      "Deleting ReasoningEngine resource: projects/28368249660/locations/us-central1/reasoningEngines/3743951441786568704\n",
      "Delete ReasoningEngine backing LRO: projects/28368249660/locations/us-central1/operations/3254580153660997632\n",
      "ReasoningEngine resource projects/28368249660/locations/us-central1/reasoningEngines/3743951441786568704 deleted.\n"
     ]
    }
   ],
   "source": [
    "remote_agent.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f133658-b2d7-41dc-be26-b8cb3484bdea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFound",
     "evalue": "404 ReasoningEngine does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.jupyter_venv_3_10/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/.jupyter_venv_3_10/lib/python3.10/site-packages/grpc/_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    270\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.jupyter_venv_3_10/lib/python3.10/site-packages/grpc/_interceptor.py:332\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interceptor\u001b[38;5;241m.\u001b[39mintercept_unary_unary(\n\u001b[1;32m    330\u001b[0m     continuation, client_call_details, request\n\u001b[1;32m    331\u001b[0m )\n\u001b[0;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, call\n",
      "File \u001b[0;32m~/.jupyter_venv_3_10/lib/python3.10/site-packages/grpc/_channel.py:440\u001b[0m, in \u001b[0;36m_InactiveRpcError.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See grpc.Future.result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.jupyter_venv_3_10/lib/python3.10/site-packages/grpc/_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n",
      "File \u001b[0;32m~/.jupyter_venv_3_10/lib/python3.10/site-packages/grpc/_channel.py:1198\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1192\u001b[0m (\n\u001b[1;32m   1193\u001b[0m     state,\n\u001b[1;32m   1194\u001b[0m     call,\n\u001b[1;32m   1195\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1196\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1197\u001b[0m )\n\u001b[0;32m-> 1198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.jupyter_venv_3_10/lib/python3.10/site-packages/grpc/_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.NOT_FOUND\n\tdetails = \"ReasoningEngine does not exist.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.250.195.42:443 {grpc_message:\"ReasoningEngine does not exist.\", grpc_status:5, created_time:\"2024-12-22T20:53:57.507221782+05:30\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mreasoning_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTell me about the weather in Coimbatore.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.jupyter_venv_3_10/lib/python3.10/site-packages/vertexai/reasoning_engines/_reasoning_engines.py:800\u001b[0m, in \u001b[0;36m_wrap_query_operation.<locals>._method\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _utils\u001b[38;5;241m.\u001b[39mJsonDict:\n\u001b[0;32m--> 800\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_api_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_reasoning_engine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maip_types\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQueryReasoningEngineRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresource_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclass_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    807\u001b[0m     output \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mto_dict(response)\n\u001b[1;32m    808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m, output)\n",
      "File \u001b[0;32m~/.jupyter_venv_3_10/lib/python3.10/site-packages/google/cloud/aiplatform_v1beta1/services/reasoning_engine_execution_service/client.py:834\u001b[0m, in \u001b[0;36mReasoningEngineExecutionServiceClient.query_reasoning_engine\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    833\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 834\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.jupyter_venv_3_10/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.jupyter_venv_3_10/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mNotFound\u001b[0m: 404 ReasoningEngine does not exist."
     ]
    }
   ],
   "source": [
    "reasoning_engine.query(message=\"Tell me about the weather in Coimbatore.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be67f419-ed00-4d7e-a1b5-575a5f090580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtc-rag-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
